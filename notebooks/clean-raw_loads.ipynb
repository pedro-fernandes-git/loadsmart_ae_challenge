{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os  \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# project_root = os.getcwd()   # root do repo ao abrir o notebook\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "csv_path = os.path.join(project_root, \"input_data\", \"loadsmart_loads_raw.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_lane(lane_value):\n",
    "    \"\"\"\n",
    "    Splits a lane value into 4 components: pickup_city, pickup_state, delivery_city, delivery_state.\n",
    "    \n",
    "    Args:\n",
    "        lane_value (str): Lane string in format \"City, ST -> City, ST\"\n",
    "                         Example: \"Los Angeles, CA -> New York, NY\"\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'pickup_city', 'pickup_state', 'delivery_city', 'delivery_state'\n",
    "\n",
    "    \"\"\"\n",
    "    if not lane_value or not isinstance(lane_value, str):\n",
    "        return {\n",
    "            'pickup_city': None,\n",
    "            'pickup_state': None,\n",
    "            'delivery_city': None,\n",
    "            'delivery_state': None\n",
    "        }\n",
    "    \n",
    "    # Split origin and destination\n",
    "    parts = lane_value.split('->')\n",
    "    if len(parts) != 2:\n",
    "        return {\n",
    "            'pickup_city': None,\n",
    "            'pickup_state': None,\n",
    "            'delivery_city': None,\n",
    "            'delivery_state': None\n",
    "        }\n",
    "    \n",
    "    origin = parts[0].strip()\n",
    "    destination = parts[1].strip()\n",
    "    \n",
    "    # Split city and state for origin (pickup)\n",
    "    origin_parts = origin.split(',')\n",
    "    pickup_city = origin_parts[0].strip() if len(origin_parts) > 0 else None\n",
    "    pickup_state = origin_parts[1].strip() if len(origin_parts) > 1 else None\n",
    "    \n",
    "    # Split city and state for destination (delivery)\n",
    "    dest_parts = destination.split(',')\n",
    "    delivery_city = dest_parts[0].strip() if len(dest_parts) > 0 else None\n",
    "    delivery_state = dest_parts[1].strip() if len(dest_parts) > 1 else None\n",
    "    \n",
    "    return {\n",
    "        'pickup_city': pickup_city,\n",
    "        'pickup_state': pickup_state,\n",
    "        'delivery_city': delivery_city,\n",
    "        'delivery_state': delivery_state\n",
    "    }\n",
    "\n",
    "\n",
    "# Helper function to apply split_lane to entire DataFrame\n",
    "def split_lane_dataframe(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Applies split_lane function to a DataFrame's 'lane' column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with a 'lane' column\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with lane column replaced by pickup/delivery columns\n",
    "    \"\"\"\n",
    "    # Apply split_lane to each row and expand into columns\n",
    "    lane_splits = df['lane'].apply(split_lane).apply(pd.Series)\n",
    "    \n",
    "    # Drop original lane column and add new columns\n",
    "    df['pickup_city'] = lane_splits['pickup_city']\n",
    "    df['pickup_state'] = lane_splits['pickup_state']\n",
    "    df['delivery_city'] = lane_splits['delivery_city']\n",
    "    df['delivery_state'] = lane_splits['delivery_state']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b258b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Use the DataFrame helper function to process all rows\n",
    "df_output = split_lane_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cast_all_columns(df: pd.DataFrame):\n",
    "\n",
    "    #Here we drop the column that is duplicated\n",
    "    df.drop(columns=['has_mobile_app_tracking.1'], inplace = True)\n",
    "    # Integers\n",
    "    df[\"loadsmart_id\"] = df[\"loadsmart_id\"].astype(\"int64\")\n",
    "    df[\"carrier_dropped_us_count\"] = df[\"carrier_dropped_us_count\"].astype(\"Int64\")  # pandas nullable int\n",
    "\n",
    "    # Numerics\n",
    "    df[\"book_price\"] = df[\"book_price\"].astype(\"float64\")\n",
    "    df[\"source_price\"] = df[\"source_price\"].astype(\"float64\")\n",
    "    df[\"pnl\"] = df[\"pnl\"].astype(\"float64\")\n",
    "    df[\"mileage\"] = df[\"mileage\"].astype(\"float64\")\n",
    "    df[\"carrier_rating\"] = df[\"carrier_rating\"].astype(\"float64\")\n",
    "\n",
    "    # Dates â†’ timestamps\n",
    "    for col in [\n",
    "        \"quote_date\", \"book_date\", \"source_date\",\n",
    "        \"pickup_date\", \"delivery_date\",\n",
    "        \"pickup_appointment_time\", \"delivery_appointment_time\"\n",
    "    ]:\n",
    "        df[col] = pd.to_datetime(df[col], format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "    # Objects -> Booelans already correct from Pandas Reading\n",
    "\n",
    "    # Strings\n",
    "    string_cols = [\n",
    "        \"equipment_type\",\"sourcing_channel\",\n",
    "        \"carrier_name\",\"shipper_name\", \"lane\",\n",
    "        \"pickup_city\",\"pickup_state\",\n",
    "        \"delivery_city\",\"delivery_state\"\n",
    "    ]\n",
    "    for col in string_cols:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all column casting\n",
    "casted_df = cast_all_columns(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f98fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "#Create connection to the database\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://loadsmart_user:loadsmart_password@localhost:5432/loadsmart_challenge\"\n",
    ")\n",
    "\n",
    "# Create schema and handle existing table with dependencies\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS analytics_cleaned\"))\n",
    "    \n",
    "    # Drop the table with CASCADE to handle dbt views that depend on it\n",
    "    # This is safe because dbt will recreate the views when you run 'dbt run'\n",
    "    try:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics_cleaned.cleaned_loads CASCADE\"))\n",
    "        print(\"Dropped existing table and dependent views (if any)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: {e}\")\n",
    "\n",
    "# Load the data\n",
    "casted_df.to_sql(\n",
    "    name=\"cleaned_loads\",\n",
    "    schema=\"analytics_cleaned\",\n",
    "    con=engine,             \n",
    "    if_exists=\"fail\",  # Changed to 'fail' since we manually dropped above\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(casted_df)} rows into analytics_cleaned.cleaned_loads\")\n",
    "print(\"\\nIMPORTANT: After loading new data, run 'dbt run' to recreate the dimensional model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c8d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
